{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "In this exercise, you are to implement logistic regression and then apply it on a datasets. \n",
    "\n",
    "The task is to build a model that gives an applicant's probability of admission based on the scores from 2 exams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load in the data and Visualize\n",
    "The first step is to load in the dataset and visualize it. However, we need to import some important libraries and define some functions before doing that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function: creates a scatter plot of the examples\n",
    "def plotData(data, label_x, label_y, label_pos, label_neg, axes=None):\n",
    "    # Get indexes for class 0 and class 1\n",
    "    neg = data[:,2] == 0\n",
    "    pos = data[:,2] == 1\n",
    "    \n",
    "    # If no specific axes object has been passed, get the current axes.\n",
    "    if axes == None:\n",
    "        axes = plt.gca()\n",
    "    axes.scatter(data[pos][:,0], data[pos][:,1], marker='+', c='k', s=60, linewidth=2, label=label_pos)\n",
    "    axes.scatter(data[neg][:,0], data[neg][:,1], c='y', s=60, label=label_neg)\n",
    "    axes.set_xlabel(label_x)\n",
    "    axes.set_ylabel(label_y)\n",
    "    axes.legend(frameon= True, fancybox = True);\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/ex2data1.txt', names=['x1','x2','y'])\n",
    "X = np.asarray(data[[\"x1\",\"x2\"]])\n",
    "y = np.asarray(data[\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.623660</td>\n",
       "      <td>78.024693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.286711</td>\n",
       "      <td>43.894998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.847409</td>\n",
       "      <td>72.902198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.182599</td>\n",
       "      <td>86.308552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.032736</td>\n",
       "      <td>75.344376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1         x2  y\n",
       "0  34.623660  78.024693  0\n",
       "1  30.286711  43.894998  0\n",
       "2  35.847409  72.902198  0\n",
       "3  60.182599  86.308552  1\n",
       "4  79.032736  75.344376  1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(data.values, 'Exam 1 score', 'Exam 2 score', 'Admitted', 'Not admitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add x0 to the feature matrix\n",
    "X = np.hstack((np.ones_like(y)[:,None],X))\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Implementation\n",
    "### 2.1 Sigmoid function\n",
    "In this part of the exercise, you are to implement the sigmoid function. Hypothesis for logistic regression is espressed as:\n",
    "\n",
    "$$h_\\theta(x) = g(\\theta^Tx)$$\n",
    "\n",
    "where $g$ is the sigmoid function defined as:\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "Your task now is to implement the sigmoid function in the code cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    result = None\n",
    "    ############ START CODE ##############\n",
    "    \n",
    "    \n",
    "    result = (1 / (1 + np.exp(-z)))\n",
    "    \n",
    "    ########### END CODE #################\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Cost function and gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, your next task is to implement the cost function and gradient\n",
    "$$ J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\big[-y^{(i)}\\, log\\,( h_\\theta\\,(x^{(i)}))-(1-y^{(i)})\\,log\\,(1-h_\\theta(x^{(i)}))\\big]$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def costFunction(theta, X, y):\n",
    "    m = y.size\n",
    "    h = sigmoid(X.dot(theta))\n",
    "    \n",
    "    J = None\n",
    "    \n",
    "    ########### START CODE ################\n",
    "    \n",
    "    J = (-1*(1/m)*(np.log(h).T.dot(y)+np.log(1-h).T.dot(1-y)))\n",
    "               \n",
    "    ########### END CODE ##################\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you are to implement the gradient of the cost function\n",
    "#### $$ \\frac{\\delta J(\\theta)}{\\delta\\theta_{j}} = \\frac{1}{m}\\sum_{i=1}^{m} ( h_\\theta (x^{(i)})-y^{(i)})x^{(i)}_{j} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(theta, X, y):\n",
    "    m = y.size\n",
    "    h = sigmoid(X.dot(theta.reshape(-1,1)))\n",
    "    \n",
    "    grad =(1/m)*X.T.dot(h-y)\n",
    "\n",
    "    return(grad.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now to test your implementation of the cost function and gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: \n",
      " [ 0.69314718]\n",
      "Grad: \n",
      " (3,)\n"
     ]
    }
   ],
   "source": [
    "initial_theta = np.zeros(X.shape[1])\n",
    "cost = costFunction(initial_theta, X, y)\n",
    "grad = gradient(initial_theta, X, y)\n",
    "print('Cost: \\n', cost)\n",
    "print('Grad: \\n', grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost should be: <br/> 0.6931471805599453<br/>\n",
    "Grad: <br/>\n",
    " [ -0.1        -12.00921659 -11.26284221]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, you found optimized the cost function to obtain the optimal parameters using your implementation of gradient descent. This time, you will use an advanced optimization function from scipy, `minimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LATITUDE\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "res = minimize(costFunction, initial_theta, args=(X,y), method=None, jac=gradient, options={'maxiter':400})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluating logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After learning the model parameters, you can now use the model to make predictions. So, let's predict the admssion probability for a student with an Exam 1 score of 45 and Exam 2 score of 85."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-25.16133284,   0.2062317 ,   0.2014716 ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admission probability is:  0.776290724059\n"
     ]
    }
   ],
   "source": [
    "prob = None\n",
    "\n",
    "########  START CODE #######\n",
    "\n",
    "z = res.x[0] + res.x[1]*45 + res.x[2]*85\n",
    "h = sigmoid(z)\n",
    "\n",
    "prob = h\n",
    "\n",
    "######## END CODE #########\n",
    "print('admission probability is: ', prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Admission probability should be 0.776"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the quality of the learned parameters by observing how well the model performs on the training set. This is done by making predictions on the training set and computing the accuracy of the model. The model's accuracy is the fraction of predictions it got right. Complete the code in the cell below to make predictions on a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(theta, X, threshold=0.5):\n",
    "    \n",
    "    ############## START CODE ##################\n",
    "    \n",
    "    p = sigmoid(X.dot(theta.T)) >= threshold\n",
    "    \n",
    "    \n",
    "    ############# END CODE ####################\n",
    "    return(p.astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the train accurracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 89.0%\n"
     ]
    }
   ],
   "source": [
    "p = predict(res.x, X) \n",
    "print('Train accuracy {}%'.format(100*sum(p == y.ravel())/p.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision boundary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x8f4add12e8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(45, 85, s=60, c='r', marker='v', label='(45, 85)')\n",
    "plotData(data.values, 'Exam 1 score', 'Exam 2 score', 'Admitted', 'Not admitted')\n",
    "x1_min, x1_max = X[:,1].min(), X[:,1].max(),\n",
    "x2_min, x2_max = X[:,2].min(), X[:,2].max(),\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max))\n",
    "h = sigmoid(np.c_[np.ones((xx1.ravel().shape[0],1)), xx1.ravel(), xx2.ravel()].dot(res.x))\n",
    "h = h.reshape(xx1.shape)\n",
    "plt.contour(xx1, xx2, h, [0.5], linewidths=1, colors='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exercise, you will implement regularized logistic regression\n",
    "to predict whether microchips from a fabrication plant passes quality assurance (QA). You are to do this using results from 2 tests.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('data/ex2data2.txt', names=['x1','x2','y'])\n",
    "X = np.asarray(data2[[\"x1\",\"x2\"]])\n",
    "y = np.asarray(data2[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.85196</td>\n",
       "      <td>-0.367690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.38537</td>\n",
       "      <td>-0.565060</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.46025</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.23675</td>\n",
       "      <td>-0.214180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.20104</td>\n",
       "      <td>-0.601610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2  y\n",
       "71  0.85196 -0.367690  0\n",
       "10  0.38537 -0.565060  1\n",
       "43  0.46025  0.012427  1\n",
       "36 -0.23675 -0.214180  1\n",
       "25  0.20104 -0.601610  1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(data2.values, 'Microchip Test 1', 'Microchip Test 2', 'y = 1', 'y = 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Feature mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit the data better, more features have to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 28)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = PolynomialFeatures(6)\n",
    "X_mapped = mapping.fit_transform(X)\n",
    "X_mapped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Cost function and gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now to implement code to compute the cost function and its gradient for regularized logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regularized Cost Function\n",
    "##### $$ J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\big[-y^{(i)}\\, log\\,( h_\\theta\\,(x^{(i)}))-(1-y^{(i)})\\,log\\,(1-h_\\theta(x^{(i)}))\\big] + \\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def costFunctionReg(theta, X, y, reg):\n",
    "    m = y.size\n",
    "    h = sigmoid(X.dot(theta))\n",
    "    \n",
    "    J = -1*(1/m)*(np.log(h).T.dot(y) + np.log(1-h).T.dot(1-y)) + (reg/(2*m))*np.sum(np.square(theta[1:]))\n",
    "    #print(J.shape)\n",
    "    \n",
    "    return(J)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gradient\n",
    "# \n",
    "##### $$ \\frac{\\delta J(\\theta)}{\\delta\\theta_{j}} = \\frac{1}{m}\\sum_{i=1}^{m} ( h_\\theta (x^{(i)})-y^{(i)})x^{(i)}_{j} + \\frac{\\lambda}{m}\\theta_{j}$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradientReg(theta,X, y, reg):\n",
    "    m = y.size\n",
    "    h = sigmoid(X.dot(theta))\n",
    "      \n",
    "    grad = (1/m)*X.T.dot(h-y) + (reg/m)*theta  #+ (reg/m)*np.r_[[[0]],theta[1:].reshape(-1,1)]\n",
    "        \n",
    "    return(grad.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_theta = np.zeros(X_mapped.shape[1])\n",
    "costFunctionReg(initial_theta, X_mapped, y, 1)\n",
    "gradientReg(initial_theta,X_mapped, y, 1).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res2 = minimize(costFunctionReg, initial_theta, args=(X_mapped, y, 1), method=None, jac=gradientReg, options={'maxiter':3000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LATITUDE\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,3, sharey = True, figsize=(17,5))\n",
    "\n",
    "# Decision boundaries\n",
    "# Lambda = 0 : No regularization --> too flexible, overfitting the training data\n",
    "# Lambda = 1 : Looks about right\n",
    "# Lambda = 100 : Too much regularization --> high bias\n",
    "\n",
    "for i, C in enumerate([0, 1, 100]):\n",
    "    # Optimize costFunctionReg\n",
    "    res2 = minimize(costFunctionReg, initial_theta, args=(X_mapped, y, C), method=None, jac=gradientReg, options={'maxiter':3000})\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = 100*sum(predict(res2.x, X_mapped) == y.ravel())/y.size    \n",
    "\n",
    "    # Scatter plot of X,y\n",
    "    plotData(data2.values, 'Microchip Test 1', 'Microchip Test 2', 'y = 1', 'y = 0', axes.flatten()[i])\n",
    "    \n",
    "    # Plot decisionboundary\n",
    "    x1_min, x1_max = X[:,0].min(), X[:,0].max(),\n",
    "    x2_min, x2_max = X[:,1].min(), X[:,1].max(),\n",
    "    xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max))\n",
    "    h = sigmoid(mapping.fit_transform(np.c_[xx1.ravel(), xx2.ravel()]).dot(res2.x))\n",
    "    h = h.reshape(xx1.shape)\n",
    "    axes.flatten()[i].contour(xx1, xx2, h, [0.5], linewidths=1, colors='g');       \n",
    "    axes.flatten()[i].set_title('Train accuracy {}% with Lambda = {}'.format(np.round(accuracy, decimals=2), C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
